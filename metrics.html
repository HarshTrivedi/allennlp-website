---
---
<!DOCTYPE html>
<html lang="en-us">
  <head>
    {% include meta.html %}
    <title>AllenNLP - Metrics</title>
  </head>

  <body data-page="metrics">
    <div id="page-content">
      {% include header.html %}
      <div class="banner banner--interior-hero">
        <div class="constrained constrained--sm">
          <div class="banner--interior-hero__content">
            <h1>Performance Metrics</h1>
            <p class="t-sm">See how our models compare to the competition. AllenNLP provides strong performance with reasonable runtimes, along with the infrastructure to easily run them.</p>
          </div>
        </div>
      </div>
      <div class="banner">
        <div class="constrained constrained--med">
          <div class="padded-med">
            <h2>SRL Benchmarks</h2>
            <p class="t-sm">SRL, or Semantic Role Labeling, models recover the latent predicate argument structure of a sentence. The build representations that support answer very basic questions about sentence meaning, including "who" did "what" to â€œwhom," etc. The AllenNLP SRL model is a reimplementation of <a href="https://homes.cs.washington.edu/~luheng/files/acl2017_hllz.pdf" target="_blank">a deep BiLSTM model (He et al, 2017)</a>. It closely matches state-of-the-art accuracy on benchmark datasets (including <a href="http://www.lsi.upc.edu/~srlconll/" target="_blank">CoNLL 2005</a> shown below), while significantly improving training and and prediction runtimes.</p>
          </div>
          <div class="scroll-box">
            <table class="metrics-table">
              <thead>
                <tr>
                  <th>System</th>
                  <th>Precision</th>
                  <th>Recall</th>
                  <th>F-Measure</th>
                  <th>GPU Speed</th>
                  <th>CPU Speed</th>
                </tr>
              </thead>
              <tbody>
                <tr class="tr--featured">
                  <td>AllenNLP</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>0.0<sub>examples/sec</sub></td>
                  <td>0.0<sub>examples/sec</sub></td>
                </tr>
                <tr>
                  <td>He</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>0.0<sub>examples/sec</sub></td>
                  <td>0.0<sub>examples/sec</sub></td>
                </tr>
                <tr>
                  <td>FitzGerald</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>0.0<sub>examples/sec</sub></td>
                  <td>0.0<sub>examples/sec</sub></td>
                </tr>
                <tr>
                  <td>Pradhan</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>0.0<sub>examples/sec</sub></td>
                  <td>0.0<sub>examples/sec</sub></td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
      <div class="banner c-bg-gray-light">
        <div class="constrained constrained--med">
          <div class="padded-med">
            <h2>Machine Comprehension Benchmarks</h2>
            <p class="t-sm">Machine Comprehension (MC) models answer natural language questions by selecting an answer span within an evidence text. The AllenNLP MC model is a reimplementation of <a href="https://www.semanticscholar.org/paper/Bidirectional-Attention-Flow-for-Machine-Comprehen-Seo-Kembhavi/007ab5528b3bd310a80d553cccad4b78dc496b02" target="_blank">BiDAF (Seo et al, 2017)</a>, or Bi-Directional Attention Flow, a widely used MC baseline that achieves near state-of-the-art accuracies. See how our implementation compares with other systems on <a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank">the SQuAD dataset</a>.</p>
          </div>
          <div class="scroll-box">
            <table class="metrics-table">
              <thead>
                <tr>
                  <th>System</th>
                  <th>Precision</th>
                  <th>Recall</th>
                  <th>F-Measure</th>
                  <th>GPU Speed</th>
                  <th>CPU Speed</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>rNET</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>0.0<sub>examples/sec</sub></td>
                  <td>0.0<sub>examples/sec</sub></td>
                </tr>
                <tr class="tr--featured">
                  <td>AllenNLP</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>0.0<sub>examples/sec</sub></td>
                  <td>0.0<sub>examples/sec</sub></td>
                </tr>
                <tr>
                  <td>BiDAF</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>0.0<sub>examples/sec</sub></td>
                  <td>0.0<sub>examples/sec</sub></td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
      <div class="banner">
        <div class="constrained constrained--med">
          <div class="padded-med">
            <h2>Textual Entailment Benchmarks</h2>
            <p class="t-sm">Textual Entailment (TE) models take a pair of sentences and predict whether the facts in the first necessarily imply the facts in the second one. The AllenNLP TE model is a reimplementation of <a href="https://www.semanticscholar.org/paper/A-Decomposable-Attention-Model-for-Natural-Languag-Parikh-T%C3%A4ckstr%C3%B6m/07a9478e87a8304fc3267fa16e83e9f3bbd98b27" target="_blank">the decomposable attention model (Parikh et al, 2017)</a>, a widely used TE baseline that is relatively simple and achieves near state-of-the-art performance. See how our implementation compares with other systems on <a href="https://nlp.stanford.edu/projects/snli/" target="_blank">the SNLI dataset</a>.</p>
          </div>
          <div class="scroll-box">
            <table class="metrics-table">
              <thead>
                <tr>
                  <th>System</th>
                  <th>Precision</th>
                  <th>Recall</th>
                  <th>F-Measure</th>
                  <th>GPU Speed</th>
                  <th>CPU Speed</th>
                </tr>
              </thead>
              <tbody>
                <tr class="tr--featured">
                  <td>AllenNLP</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>0.0<sub>examples/sec</sub></td>
                  <td>0.0<sub>examples/sec</sub></td>
                </tr>
                <tr>
                  <td>Parikh</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>00.0</td>
                  <td>0.0<sub>examples/sec</sub></td>
                  <td>0.0<sub>examples/sec</sub></td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
      {% include footer.html %}
    </div>
    {% include svg-sprite.html %}
    {% include scripts.html %}
  </body>
</html>
